{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjtirCJZF01L",
        "outputId": "d8be5d9a-1125-425d-b3a7-1827c3ecf3a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (1.10.1)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader \n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrdnwE-Ckd6z"
      },
      "source": [
        "# Q1 gradient descent로 simple linear regression 추정하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV3I2XODkzpq"
      },
      "source": [
        "예제로 사용할 데이터 생성하기\n",
        "\n",
        "$ y_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i \\quad \\epsilon_i \\sim  iid N(0, 1)$ \n",
        "\n",
        "$ \\beta_0 = 5, \\beta_1 = 2$라는 모형을 따르는 데이터를 생성해준다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "DJuJTVrQmFel",
        "outputId": "dd10503e-bd27-41f6-8fce-26154b0c8e07"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYyklEQVR4nO3df4xldXnH8c+zy1QHtR0MK11GtrtNCP4i7tqJpZ3E6FILSiMriaUkWlJN1j+0FUJoRv+RxDZMghFN2jRFpWJK6BqhSFgjNawpcdPQzrLbgl2JRkAZtuwSdpSUsQ7L0z/m3uXO2fO993vu+XHPj/crITtz58493xvguc8+5/k+X3N3AQCaZ9OkFwAAGA8BHAAaigAOAA1FAAeAhiKAA0BDnVXlxc4991zfvn17lZcEgMY7dOjQc+6+Jfl4pQF8+/btWlpaqvKSANB4ZvZU2uOUUACgoQjgANBQBHAAaCgCOAA0FAEcABqq0i4UAGi7ew8v65YHHtczK6s6f2ZaN152kfbsmi3lWgRwACjIvYeX9el7HtXq2ilJ0vLKqj59z6OSVEoQp4QCAAW55YHHTwfvvtW1U7rlgcdLud7IAG5mF5jZ98zsqJn9wMw+1Xv8JjNbNrMjvX/eX8oKAaAhnllZzfR4XjEllJck3eDuj5jZ6yQdMrPv9n52q7t/vpSVAUDDnD8zreWUYH3+zHQp1xuZgbv7MXd/pPf1C5KOSiqnIg8ADXbjZRdpemrzhsemNple/NVL2rGwX/OLB3Tv4eXCrpepBm5m2yXtkvRw76FPmtl/mdntZnZO4Hf2mtmSmS2dOHEi32oBoMb27JrVzVddrNmZaZmkmekpyaSTL67J9cpNzaKCuMWeiWlmr5X0r5L+2t3vMbPzJD0nySV9TtJWd//osNeYm5tzhlkB6Ir5xQOpJZXZmWkdXNgd/Tpmdsjd55KPR7URmtmUpLsl3enu90iSuz878PMvS7o/ejUA0EBZe7zLvqkZ04Vikr4q6ai7f2Hg8a0DT/ugpMcKWREA1FC/x3t5ZTW6HBK6eVnUTc2YDHxe0kckPWpmR3qPfUbSNWa2U+sllCclfbyQFQHAhKVl2sN6vENZ+I2XXbRhY48kTU9t1o2XXVTIOkcGcHf/viRL+dG3C1kBANRAP2gvr6zKtJ6ZSq9k2sng3TesHNIP7GVtrY++iVkEbmICqKPkFvg0m810KhAvZ0ueeRK6iclWegCdl1YeSTrlfkaPd1/R7YGxCOAAOi+mK2R2Zvp0j3eaMmeehBDAAXTeqK6Q/o3HPbtmdXBhd+pNQam8mSchBHAAnZe2Bb4fpPuZ92B9OxTwXSp8u/wwzAMH0HlZu0XS2gP7yp4BPogADgBaD7axAXcw4KdtlR/VH14UAjiARqvyCLNB/YC/Y2G/0poLq6iHUwMH0FjjbG8vWtnb5YchAwfQKIMZ96aUzTWD7XxVZOZlb5cfhgAOoDGSOyZDOyOT29/LvLFY9nb5YQjgABojZsektL7tPWbwVFH18yw3QItEAAfQGDE3BqenNkcNnkpm81W2/xWFm5gAGiN0Y3CzmUyjt7sP/v6w8bBNQQYOoDFCNwyTOyUljbyxWPZpOVUggANojNgbhjHPO39mOnUTTjLLn1SfeQzmgQPopLQZ4MlsPuY5VWAeOAAM2LNr9nS9fLB+PhiY614np4QCoLNGtf/VvU5OAAdQS3WoPcfWySeFAA6gNOMG4aJ7tMddxyS3ycegBg6gFHkGTRVZe86zjpg6+SSRgQMoxbAgPCoAFll7Dq3jun1HdMsDj4/Mxie1TT4GARxAKfIE4XFrz2mlkmHXa+L2+UGUUACc4d7Dy5pfPKAdC/vHPuMxz7mRoTMql1dWg78bKpXMnD01dJ11agvMigAOYIOiDklIC8J9odfsf3Bcv++IXnXWJp3TC74mnT71JvS7oVKJu4Lr6KtLW2BWBHAAGxR1A3HwBmCa5GsmPzhWVtf0y7WXdc7ZU2ccWZa2nlAQ/vnq2tB1SPVpC8yKAA5gg1AgHFa+CNmza1YHF3bLIq4V+uA4+eJa1DqHHW3WX8cXr955RjZep7bArAjgADYYlo2OW06JOTcyaxkj+ZppJZtkcK57W2BWdKEA2CBt88qg2FbAUa+ZDK6hzpOZ6Sn930svj9xMk2VSYVMDdhIBHMAGg4EwLaBK2bPlmOAaCvI3feCtI3938DptCc4xGCcLIGh+8UBqEJ+dmdbBhd2FX68O80/qKDROlgwcQFDVs0C6lkHnRQAHEBRbV86KTLsYBHAAQxWdFbfhNPi6oI0QQKXqfspNkxDAAVSq7qfcNMnIEoqZXSDp65J+U9LLkm5z9y+Z2esl7ZO0XdKTkv7Y3U+Wt1QA46i63jzqenU/5aZJYjLwlyTd4O5vlnSJpE+Y2VskLUh60N0vlPRg73sANVLUYKoirzfOpEGkGxnA3f2Yuz/S+/oFSUclzUq6UtIdvafdIWlPSWsEMKaq680x10sOuYqZNIh0mWrgZrZd0i5JD0s6z92PSetBXtIbCl8dgFxi681FzP/Ocr3+cKnZmemoSYNIFx3Azey1ku6WdJ27/yLD7+01syUzWzpx4sQ4awQwppghUkWWWWKuN4gbmvlEBXAzm9J68L7T3e/pPfysmW3t/XyrpONpv+vut7n7nLvPbdmypYg1A4gUM6GvyDJLzPUGZQ342GhkADczk/RVSUfd/QsDP7pP0rW9r6+V9K3ilwcgj5jxqUVmwVnHtWYN+NgoZifmvKSPSHrUzI70HvuMpEVJ3zCzj0n6qaQPlbJCALmM2klZRFvfuK2KZW3V74qRAdzdvy8FD9S4tNjlAKha3oFVebfGM8BqfMxCARqgzM04ebPgYTV0AnO5COBAzVUx/GmcLLj/oVLUoQ/IjgAODFGHsadFZrhFvZ/kh0oaOknKRwAHAuoy9rSoLpEi3s+orLuPTpJqMI0QCKjL2NOieqXzvp/BDT/DNP2k9yYhgAMBddklWFSvdN73k/YBkNQ/K5PgXQ0COBBQl12CWTfHhOR9P6MCPWWT6lEDBwKqPtB3mCJ6pfO+n9CGH2n9Q4UNONUjgAMBk9glWOd+79AHAPXuyTH35DDH8szNzfnS0lJl1wOaJK01rz8ruy4Zbh3aKrvIzA65+1zycTJwoCbSbhImDzqQimthHCcYs+29XgjgQE5FZaWjbhKO2ryTZR116XFHPnShADlUcRjCoFCQz7qOuvS4Ix8COJBDbCCMObIsrd87KRnk+6973b4jmQJyXXrckQ8lFCCHmEAYW64Y7BJZXlndcNivdGbLX8w8ktD6ipgBjskjAwdyiNkck6Vc0T/s98nFK3Tr1TuHbt6J2RkZWh8n4bQDGTiQQ8zmmHHLFaGOjyIGSnESTjsQwIEcYgLhqHJFnu6RkJi+cVoCm4+NPEDJ0oJufwejpEy7G+cXDwzNvAdfl+y6PUIbeaiBAyUbNowqazvfsLJL/3UlFdbaiHqjhAJUIFSuyFofD5Vj+mNcpfUsnTMqu4EMHJigrCNeY7pH6PHuDgI4MEFZ2/liZoPXZY45ykcJBZigcdr5RnWP1GmOOcpFAAcilTVKteh2Pnq8u4MADkQYZ3rfJGdn0+PdDdTAgQhZ2/2KnFIIhBDAgQhZOzsY14oqUEIBNLrckXV6H618qAIZODovptyRtd2PVj5UgQCOzguVO67bd+T04Qsx/deDGNeKKlBCQecNK2sku01iOzto5UMVCODovFB9u2/cOSLDAv4kWwzRHpRQ0HkxZ1EWefORFkMUhQwctVRlhpo8izJNkTcfh7UYkoUjCwI4amecXY/jXif5ISGlH7BQ5M1HWgxRFAI4amfUJpgiMvPQh8TNV12sm6+6eOxrxPzNgRPhURQCOGonlIn2g2wRmfmwD4mDC7sL/VBIro9pgSjKyJuYZna7mR03s8cGHrvJzJbN7Ejvn/eXu0x0SSgT3WxW2Pb0MsoYsdvns/aUAyExGfjXJP2NpK8nHr/V3T9f+IrQeaEMNXQSe1rQLXprfIwsHwpMC0QRRmbg7v6QpOcrWAsgKZyhzkZuTy9ja3wMts+janlq4J80sz+VtCTpBnc/mfYkM9sraa8kbdu2Lcfl0CWhDDWmdhzTplfGTklq26iaufvoJ5ltl3S/u7+t9/15kp6T5JI+J2mru3901OvMzc350tJSrgWj22K6PHYs7Ffaf9Um6YnFKya+PiArMzvk7nPJx8fKwN392YEX/rKk+3OsDYgWUzueZJsetW1Uaayt9Ga2deDbD0p6LPRcoGpMAkRXjMzAzewuSe+WdK6ZPS3ps5LebWY7tV5CeVLSx8tbIpANkwDRFVE18KJQA8ekUaNGExVaAweaqMgZK3wQoA4I4Gi9frBNu7E5zhTAqoZtAaMwDxytNripJyTr9nlOnEddEMDRamnBNilreyHjYFEXlFBQiVDNuOxa8qigOk57IeNgURcEcJQuVDNeeup53X1oudRa8rDzLmfH/MBgyzzqghIKSheqGd/18M9KryWHNvV88eqdY8/9Zhws6oIMHKULlTFOBfYgFFlLLmtTD1vmUQcEcJQuVMbYbJYaxF3S/OKBwurhBFu0FSUUlC5Uxrjmdy844/G+tBneSfceXtb84gHtWNiv+cUDQ58LtBEBHKUL1Yz/as/FQw9qGFYPjzm0AWg7ZqGgFrLO8J5fPBAsy7zszvZ2tEpoFgoZOGoh63Fkw26MkpGjKwjgqIWsM7xjNs2wvR1tRwBHLWTtrU4L+GnY3o42o40QtZGl3S/Z370p0JLI9na0GQEcQbFzSgaf9xvTUzKTVl5cK/1G4mDAT27Xl9jejvYjgCNV7Mzr5PNWVtdO/2zY75SxM1LiGDV0C22ESBVq05udmdbBhd0jnxf6nVCmzCwRIIw2QmQSO/M65ibh4HM4DAEoDgEcqWL7smNuEg4+h8MQgOIQwJEqti97VDtf8neybtgBEMZNTGyQ7Ch59dSmoR0lyZuHo7pQOAwBKA4BHKeldZRMT23WrVfvHHqDMU//dky3SNnHrgFNRQDHacNuMCYDZp6gmiXgx7YzAl1EAG+hcYNr7A3GKoNqlg8VoGu4idkyeeZkx95grLIVkK4VIIwA3jJ5gmts50mVQZWuFSCMAN4yeYJr7ETA2KBaxJFnWcfMAl1CDbxlQgcIx2asw24w9mvryyurMmnDCTrJoFpUnZwZJ0AYAbxlxumzjrnpmQzILp0O4rMpv1PkzUdOlQfSEcBbJmvGGpsppwXkfvAeHG7Vx81HoHwE8BYKZaxpmXZsppw1IOct5QAYjZuYHRFqLwyNgk0G5qzdINx8BMpHAG+JUR0foUw7JBmYswbkrGdcAsiOEkoLxNSxs9Se0wLzON0g3HwEykUAb4GYOnaoJp2U1lHSR0AG6mVkCcXMbjez42b22MBjrzez75rZj3p/nlPuMjFMzA3GUXO7pfW2wIMLuwnSQEPE1MC/JunyxGMLkh509wslPdj7HhMy7AZjvzZ+/b4jetVZm3TO2VOZXwdAPY0M4O7+kKTnEw9fKemO3td3SNpT7LKQRegG43vetGVD58nK6pp+ufayPnzJNjpEgBYYtwZ+nrsfkyR3P2Zmbwg90cz2StorSdu2bRvzcu2VPAFn2Gk2IaEbjKHa+Pd+eEI3X3Ux29OBhjN3H/0ks+2S7nf3t/W+X3H3mYGfn3T3kXXwubk5X1paGn+1LZPsHkmantqcq/Vux8J+pf3bNUlPLF4x1msCqJ6ZHXL3ueTj4/aBP2tmW3svvFXS8TyL66q0DHnQ6topXbfvyNiT/BjFCrTbuAH8PknX9r6+VtK3illOt8T2Zmc5lGEQuyGBdotpI7xL0r9JusjMnjazj0lalPReM/uRpPf2vkdGWTLhcU68YTck0G4jb2K6+zWBH11a8Fo6J2306zBpZ1OOuhHJ5hugvdiJOUHJ7pF+F8rJF9dSn++S5hcPnC6BcFo70G1RXShFoQslTkx3yqunNqUG+tB8bgDNFepCIQOvQEypY9BgZp42v2R17VQwuHNgAtAdjJMtWWgO96iOkj27ZnVwYbcs4/VoEQS6gwBesmGTAmOEAvLM9BQtgkDHEcBzGnWQQt6zIUO93Dd94K20CAIdRw08h5iDFPKeDTnqIAUCNtBdZOA5xJRHitgN2a+HP7F4xekhVaGMH0B3kIHnEFMeGecospCYjB9AdxDAc4gtjwzuhuy3FF6/70jmYB5zdBqA7qCEkkPW8si4LYV9eW+IAmgXMnCNf6hC1vJI3gw67w1RAO3S+QCerCuvrL6yPT2mxpxlWFQRLYXJLfb0fgPd1fkSSsyhCrGbbkb1hOc9YIHxsAAGdT4Dj8l+Y54T0yFSRAbNeFgAfZ3PwGOy35jnxPSEk0EDKFLnM/BRhyrEZsix9W0yaABF6XwGnsyKZ6andM7ZU5kz5FCW3j+EgR2TAIrW2Qw864zuUYZl8uyYBFCGTmbgeTfUpBnM5NOMcygxAAzTyQA+zozuUS2C0uhDGNgxCaBInQzgWTfUZM3Y8/Z7A0CMTgbwrAE2a8ZexAhZABilkwE8a4DNmrHT7w2gCq3rQonpLsk6hCo0RKrfIhi6BgEbQJnM3Su72NzcnC8tLZX2+snt7NJ6Zp03+0173UFFXAMAQszskLvPJR9vbAaelmmXdeDBYMaelolzqAKASWhUAO8H7eWVVZnWSxjSK10hoQy5iPa9fklkx8J+pf2dhRZBAFVrTABPljGSQXR17ZQ2m+lUSkmo311SxO5LDlUAUBeN6UIZNbdbkk65B7tLitp9SYsggLpoTACPLVG86qxNqcOoxtl9mYYWQQB10ZgSSqh0kbSyuqbpqc269eqdG4JqkQcC0yIIoA4ak4GnlS5CM0fSMmu2twNom8YE8LTSxa1X74weHEXtGkDbNKaEIqWXLkK92cnMOuvuS6n4meEAUKRGBfA0WQ4KzlK7jjmkGAAmqTEllJCyukKK6loBgLI0PgOXyukKKbJrBQDKkCuAm9mTkl6QdErSS2nDVpqKHZcA6q6IEsp73H1nm4K3RNcKgPprRQmlDON0rQBAlXLNAzezJySd1Ppsqb9399tSnrNX0l5J2rZt2+889dRTY18PALooNA88bwll3t3fIel9kj5hZu9KPsHdb3P3OXef27JlS87LAQD6cpVQ3P2Z3p/HzeyfJb1T0kNFLKyPzTQAkG7sDNzMXmNmr+t/LekPJT1W1MIkFTYCFgDaKE8J5TxJ3zez/5T075L2u/t3ilnWOjbTAEDY2CUUd/+JpLcXuJYzsJkGAMJq3UZYxGYaaugA2qrWs1Dybqahhg6gzWodwPMOqqKGDqDNal1CkfINqqKGDqDNap2B58UxagDarNUBnIFUANqs9iWUPBhIBaDNWh3ApXIOewCAOmh1CQUA2owADgANRQAHgIYigANAQxHAAaChch2plvliZickjXum2rmSnitwOU3Ae+4G3nM35HnPv+XuZxxpVmkAz8PMltLOhGsz3nM38J67oYz3TAkFABqKAA4ADdWkAH7bpBcwAbznbuA9d0Ph77kxNXAAwEZNysABAAMI4ADQUI0I4GZ2uZk9bmY/NrOFSa+nbGZ2gZl9z8yOmtkPzOxTk15TFcxss5kdNrP7J72WKpjZjJl908x+2Pt3/XuTXlPZzOz63n/Tj5nZXWb26kmvqWhmdruZHTezxwYee72ZfdfMftT785wirlX7AG5mmyX9raT3SXqLpGvM7C2TXVXpXpJ0g7u/WdIlkj7RgfcsSZ+SdHTSi6jQlyR9x93fJOntavl7N7NZSX8hac7d3yZps6Q/meyqSvE1SZcnHluQ9KC7Xyjpwd73udU+gEt6p6Qfu/tP3P1Xkv5J0pUTXlOp3P2Yuz/S+/oFrf+P3eqh5mb2RklXSPrKpNdSBTP7dUnvkvRVSXL3X7n7ykQXVY2zJE2b2VmSzpb0zITXUzh3f0jS84mHr5R0R+/rOyTtKeJaTQjgs5J+NvD902p5MBtkZtsl7ZL08ISXUrYvSvpLSS9PeB1V+W1JJyT9Q69s9BUze82kF1Umd1+W9HlJP5V0TNLP3f1fJruqypzn7sek9QRN0huKeNEmBHBLeawTvY9m9lpJd0u6zt1/Men1lMXM/kjScXc/NOm1VOgsSe+Q9HfuvkvS/6qgv1bXVa/ue6WkHZLOl/QaM/vwZFfVbE0I4E9LumDg+zeqhX/tSjKzKa0H7zvd/Z5Jr6dk85I+YGZPar1EttvM/nGySyrd05Kedvf+36y+qfWA3mZ/IOkJdz/h7muS7pH0+xNeU1WeNbOtktT783gRL9qEAP4fki40sx1m9mtav+lx34TXVCozM63XRo+6+xcmvZ6yufun3f2N7r5d6/9+D7h7qzMzd/8fST8zs4t6D10q6b8nuKQq/FTSJWZ2du+/8UvV8hu3A+6TdG3v62slfauIF639ocbu/pKZfVLSA1q/a327u/9gwssq27ykj0h61MyO9B77jLt/e3JLQgn+XNKdvcTkJ5L+bMLrKZW7P2xm35T0iNY7rQ6rhVvqzewuSe+WdK6ZPS3ps5IWJX3DzD6m9Q+yDxVyLbbSA0AzNaGEAgBIQQAHgIYigANAQxHAAaChCOAA0FAEcABoKAI4ADTU/wMeRgLPa0O97QAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "x_train_np = np.linspace(0, 10, 100).reshape(-1, 1)\n",
        "y_train_np = 2 *  x_train_np + 5 + norm.rvs(0, 1, size = len(x_train_np)).reshape(-1, 1)\n",
        "\n",
        "plt.scatter(x_train_np, y_train_np)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdABaEaimr-s"
      },
      "source": [
        "$ \\hat{y_i} = \\beta_0 + \\beta_1 \\times x_i $\n",
        "\n",
        "$ \\hat{y_i} = bias + weight \\times x_i $\n",
        "\n",
        "gradient descent를 사용해 bias와 weight를 학습해보자. \n",
        "\n",
        "1) 추정된 bias와 weight의 결과값은 얼마인가? 그래프를 그려 실제 회귀식에 가깝게 추정되었는지를 확인해보자. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lt6LWxJRmTls"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 W: 1.838, b: 0.301 Cost: 260.121216\n",
            "Epoch  100/1000 W: 2.402, b: 2.310 Cost: 3.158217\n",
            "Epoch  200/1000 W: 2.230, b: 3.453 Cost: 1.782672\n",
            "Epoch  300/1000 W: 2.126, b: 4.149 Cost: 1.274237\n",
            "Epoch  400/1000 W: 2.062, b: 4.571 Cost: 1.086307\n",
            "Epoch  500/1000 W: 2.024, b: 4.829 Cost: 1.016844\n",
            "Epoch  600/1000 W: 2.000, b: 4.985 Cost: 0.991168\n",
            "Epoch  700/1000 W: 1.986, b: 5.080 Cost: 0.981678\n",
            "Epoch  800/1000 W: 1.977, b: 5.138 Cost: 0.978170\n",
            "Epoch  900/1000 W: 1.972, b: 5.173 Cost: 0.976874\n",
            "Epoch 1000/1000 W: 1.969, b: 5.194 Cost: 0.976394\n"
          ]
        }
      ],
      "source": [
        "x_train = torch.FloatTensor(x_train_np)\n",
        "y_train = torch.FloatTensor(y_train_np)\n",
        "\n",
        "W = torch.zeros(1, requires_grad = True) # Weight\n",
        "b = torch.zeros(1, requires_grad = True) # bias\n",
        "\n",
        "optimizer = optim.SGD([W, b], lr = 0.01)\n",
        "\n",
        "n_epochs = 1000\n",
        "for epoch in range(n_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = W * x_train + b\n",
        "  \n",
        "    # cost 계산: MSE\n",
        "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'\\\n",
        "            .format(epoch, n_epochs, W.item(), b.item(), cost.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "CLKgfvzhaDu4",
        "outputId": "7c6df380-e78a-4df0-e514-1ed06fbab5f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x28ce504c160>]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_pred = W * x_train + b # 추정한 회귀식\n",
        "y_real = 2 * x_train + 5 # 실제 회귀식\n",
        "\n",
        "plt.plot(x_train_np, y_pred.detach().numpy())\n",
        "plt.plot(x_train_np, y_real.detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNA2S1mmqEvc"
      },
      "source": [
        "2) learning rate를 0.03으로 조정해보자. 어떠한 문제가 발생하는가?\n",
        "\n",
        "답: cost(MSE)가 최소가 되는 점을 찾지 못하고 발산한다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4gRKC_F_qcqM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 W: 4.807, b: 0.161 Cost: 138.919205\n",
            "Epoch  100/1000 W: 441.290, b: 70.059 Cost: 6066743.000000\n",
            "Epoch  200/1000 W: 94725.391, b: 14247.596 Cost: 282261258240.000000\n",
            "Epoch  300/1000 W: 20431730.000, b: 3072123.500 Cost: 13132494941454336.000000\n",
            "Epoch  400/1000 W: 4407060992.000, b: 662646720.000 Cost: 610991820971310055424.000000\n",
            "Epoch  500/1000 W: 950597189632.000, b: 142932115456.000 Cost: 28426956043949510548783104.000000\n",
            "Epoch  600/1000 W: 205042443354112.000, b: 30830216871936.000 Cost: 1322587816248976995082875961344.000000\n",
            "Epoch  700/1000 W: 44227314061410304.000, b: 6650031008382976.000 Cost: 61534453892603740136128154083262464.000000\n",
            "Epoch  800/1000 W: 9539787294072897536.000, b: 1434405002532618240.000 Cost: inf\n",
            "Epoch  900/1000 W: 2057716343318786342912.000, b: 309398244378399473664.000 Cost: inf\n",
            "Epoch 1000/1000 W: 443844839343313326702592.000, b: 66736618099787459198976.000 Cost: inf\n"
          ]
        }
      ],
      "source": [
        "# 직접 W와 b를 정의하지 않고, nn.Module을 사용해 손쉽게 선형 모델을 생성할 수 있습니다. \n",
        "# 입출력값의 차원을 생각해 in_features와 out_features의 값을 적절하게 지정해주세요\n",
        "\n",
        "in_features = 1\n",
        "out_features = 1\n",
        "\n",
        "model = nn.Linear(in_features = in_features, out_features = out_features, bias = True)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.03)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "    \n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        params = list(model.parameters())\n",
        "        W = params[0].item()\n",
        "        b = params[1].item()\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W, b, cost.item()\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoLOBBP4tBgc"
      },
      "source": [
        "3) learning rate를 0.00000001로 조정해보자. 어떠한 문제가 발생하는가?\n",
        "\n",
        "답: cost가 최소가 되는 점을 찾기까지 시간이 오래걸린다. epoch수를 늘리면 찾을수도 있지만 비효율적이다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L8OdKyqtNGq",
        "outputId": "532ff27f-e57a-4175-b1e6-5cc9332370bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 W: 0.000, b: 0.000 Cost: 260.121216\n",
            "Epoch  100/1000 W: 0.000, b: 0.000 Cost: 260.086548\n",
            "Epoch  200/1000 W: 0.000, b: 0.000 Cost: 260.051849\n",
            "Epoch  300/1000 W: 0.001, b: 0.000 Cost: 260.017151\n",
            "Epoch  400/1000 W: 0.001, b: 0.000 Cost: 259.982422\n",
            "Epoch  500/1000 W: 0.001, b: 0.000 Cost: 259.947784\n",
            "Epoch  600/1000 W: 0.001, b: 0.000 Cost: 259.913086\n",
            "Epoch  700/1000 W: 0.001, b: 0.000 Cost: 259.878387\n",
            "Epoch  800/1000 W: 0.001, b: 0.000 Cost: 259.843750\n",
            "Epoch  900/1000 W: 0.002, b: 0.000 Cost: 259.809082\n",
            "Epoch 1000/1000 W: 0.002, b: 0.000 Cost: 259.774445\n"
          ]
        }
      ],
      "source": [
        "W = torch.zeros(1, requires_grad = True) # Weight\n",
        "b = torch.zeros(1, requires_grad = True) # bias\n",
        "\n",
        "optimizer = optim.SGD([W, b], lr = 0.00000001)\n",
        "\n",
        "n_epochs = 1000\n",
        "for epoch in range(n_epochs + 1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  hypothesis = x_train * W + b \n",
        "  \n",
        "  # cost 계산: MSE\n",
        "  cost = torch.mean((hypothesis - y_train)**2) \n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "      print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "      ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwmayIyvdT5W"
      },
      "source": [
        "# Q2. train set and test set - MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qckEHyW-t_EQ"
      },
      "source": [
        "MNIST dataset을 불러온다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u85modI7dZgP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "9913344it [00:01, 9466545.94it/s]                              \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "29696it [00:00, 9928581.23it/s]          \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1649664it [00:06, 242150.66it/s]                             \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5120it [00:00, ?it/s]                   "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "data_loader = DataLoader(dataset = mnist_train,\n",
        "                         batch_size = 100, \n",
        "                         shuffle = True\n",
        "                         )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIuf-1TTuJkB"
      },
      "source": [
        "1) epoch 수를 15로 설정하여 trainset을 훈련시켜보자. \n",
        "\n",
        "그 후 훈련시킨 모델로 testset에 대한 평가를 진행해보자. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a16aNA_xfH12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0001 cost = 0.537330985\n",
            "Epoch: 0002 cost = 0.359059513\n",
            "Epoch: 0003 cost = 0.331334144\n",
            "Epoch: 0004 cost = 0.316433430\n",
            "Epoch: 0005 cost = 0.307319254\n",
            "Epoch: 0006 cost = 0.300115943\n",
            "Epoch: 0007 cost = 0.294999033\n",
            "Epoch: 0008 cost = 0.290791422\n",
            "Epoch: 0009 cost = 0.287469208\n",
            "Epoch: 0010 cost = 0.284666836\n",
            "Epoch: 0011 cost = 0.281874001\n",
            "Epoch: 0012 cost = 0.279690772\n",
            "Epoch: 0013 cost = 0.277972311\n",
            "Epoch: 0014 cost = 0.275999486\n",
            "Epoch: 0015 cost = 0.274480402\n"
          ]
        }
      ],
      "source": [
        "# train model with train sets\n",
        "\n",
        "# 입출력값의 차원을 생각해 in_features와 out_features의 값을 적절하게 지정해주세요\n",
        "\n",
        "in_features = 28*28\n",
        "out_features = 10\n",
        "linear = torch.nn.Linear(in_features = in_features, out_features=out_features, bias = True)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n",
        "\n",
        "training_epochs = 15\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = len(data_loader)\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28)\n",
        "        Y = Y\n",
        "\n",
        "        # H(x) 계산\n",
        "        hypothesis = linear(X)\n",
        "\n",
        "        # cost 계산\n",
        "        cost = criterion(hypothesis, Y)\n",
        "\n",
        "        #cost로 H(x) 개선\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "piNVdn75gLKd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8805000185966492\n",
            "cost: 0.004604272078722715\n"
          ]
        }
      ],
      "source": [
        "# Test the model using test sets\n",
        "with torch.no_grad(): # torch.no_grad()를 사용하는 이유를 간단하게 설명해봅시다. \n",
        "\n",
        "    X_test = mnist_test.data.view(-1, 28 * 28).float()\n",
        "    Y_test = mnist_test.targets\n",
        "\n",
        "    prediction = linear(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())\n",
        "    print('cost:', cost.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkFfH5tsuY-G"
      },
      "source": [
        "2) epoch 수를 30으로 설정하여 trainset을 훈련시켜보자. \n",
        "\n",
        "그 후 훈련시킨 모델로 testset에 대한 평가를 진행해보자. \n",
        "\n",
        "어떠한 문제가 발생하는가?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcrYS0wVhMlm"
      },
      "outputs": [],
      "source": [
        "linear = torch.nn.Linear(784, 10, bias = True)\n",
        "criterion = torch.nn.CrossEntropyLoss()   \n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n",
        "\n",
        "training_epochs = 30\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = len(data_loader)\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        X = X.view(-1, 28 * 28)\n",
        "        Y = Y\n",
        "\n",
        "        # H(x) 계산\n",
        "        hypothesis = linear(X)\n",
        "\n",
        "        # cost 계산\n",
        "        cost = criterion(hypothesis, Y)\n",
        "\n",
        "        #cost로 H(x) 개선\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g-hNozohXlQ"
      },
      "outputs": [],
      "source": [
        "# Test the model using test sets\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float()\n",
        "    Y_test = mnist_test.test_labels\n",
        "\n",
        "    prediction = linear(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    \n",
        "    print('Accuracy:', accuracy.item())\n",
        "    print('cost:', cost.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0mGZ5CpmCqK"
      },
      "source": [
        "# Q3. XOR problem with multilayer perceptron\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "v2HZ6xpRph0T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.7627041339874268\n",
            "100 0.6931741833686829\n",
            "200 0.6929923892021179\n",
            "300 0.6927019953727722\n",
            "400 0.6918562054634094\n",
            "500 0.6871405839920044\n",
            "600 0.6400769352912903\n",
            "700 0.4901672601699829\n",
            "800 0.16998550295829773\n",
            "900 0.07093490660190582\n",
            "1000 0.04269516468048096\n"
          ]
        }
      ],
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = torch.FloatTensor([[1], [0], [0], [1]])\n",
        "\n",
        "# 입출력값의 차원을 고려하여 아래 빈칸을 적절하게 채워주세요\n",
        "linear1 = torch.nn.Linear(2, 2, bias = True)\n",
        "linear2 = torch.nn.Linear(2, 1, bias = True)\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "# 딥러닝의 구조를 고려하여 multi perceptron 모델을 적절하게 생성하세요. \n",
        "# nn.Sequential 함수를 사용하세요\n",
        "model =  torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid)\n",
        "\n",
        "# 이 예제에서 cross entropy 대신 BCE를 사용하는 이유를 간단하게 설명하세요\n",
        "criterion = torch.nn.BCELoss() \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
        "\n",
        "for step in range(1001):\n",
        "  hypothesis = model(X)\n",
        "  cost = criterion(hypothesis, Y)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  if step%100 == 0:\n",
        "    print(step, cost.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Hypothesis:  [[0.95920366]\n",
            " [0.05844949]\n",
            " [0.0331317 ]\n",
            " [0.96607643]] \n",
            "Correct:  [[1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]] \n",
            "Accuracy:  1.0\n"
          ]
        }
      ],
      "source": [
        "# Accuracy computation\n",
        "# True if hypothesis>0.5 else False\n",
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXzoKyGxv-aA"
      },
      "source": [
        "##Q4. Sine Function Approximation using the Legendre *Polynomial*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B_VVc1nwJnb"
      },
      "source": [
        "n = 3일때 르장드르 다항식은 다음과 같다. \\\n",
        "$ P_{3} = \\frac{1}{2} (5x^{3} -3x) $ \\\n",
        "이 함수를 사용하여, sine함수를 근사하도록 학습하려고 한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE8kJ2AlwJ0B"
      },
      "source": [
        "1) Forward, Backward 함수를 직접 작성하여보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "IxykoRYDwIgA"
      },
      "outputs": [],
      "source": [
        "# 이 클래스에서, forward, backward 함수가 하는 기능이 무엇인지 설명해주세요.\n",
        "\n",
        "class Legendre3Function(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        return grad_output * 0.5 * (15 * input ** 2 - 3)\n",
        "        # Hint : Legendre Polynomial의 differential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrvjDnuxyGP9"
      },
      "source": [
        "2) 학습을 위한 parameter와 Data를 세팅해보자.\n",
        "   우리가 사용하려는 모델은 다음과 같다.\\\n",
        "   $ y = a + b * P_{3}(c + d * x) $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "QeHfE-6tyFSx"
      },
      "outputs": [],
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x) # Target function to approximate\n",
        "\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKPsQrW5ywjW"
      },
      "source": [
        "3) 1)에서 정의한 forward, backward 함수를 사용하여,\n",
        "   딥러닝 학습 과정을 직접 작성해보자.\\\n",
        "   \\\n",
        "   Learning rate의 경우, 5e-2, 5e-4, 5e-6, 5e-8 중,\n",
        "   가장 적절한 Learning rate를 찾아보자. \\\n",
        "   적절한 learning rate보다 learning rate가 크거나 작을 때,\n",
        "   어떤 현상이 발생하는지 살펴보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "bivK3PSHyjyL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 0.23095129430294037\n",
            "100 0.1509966403245926\n",
            "200 0.14725176990032196\n",
            "300 0.14441931247711182\n",
            "400 0.1416771560907364\n",
            "500 0.13899119198322296\n",
            "600 0.13635893166065216\n",
            "700 0.13377919793128967\n",
            "800 0.13125082850456238\n",
            "900 0.1287727952003479\n",
            "1000 0.12634404003620148\n",
            "1100 0.12396357953548431\n",
            "1200 0.12163046002388\n",
            "1300 0.11934355646371841\n",
            "1400 0.11710204184055328\n",
            "1500 0.11490498483181\n",
            "1600 0.11275143176317215\n",
            "1700 0.11064045876264572\n",
            "1800 0.10857129096984863\n",
            "1900 0.10654299706220627\n",
            "Result: y = 8.033133047646857e-10 + -1.2193704843521118 * P3(-2.7714635031372836e-09 + 0.2458818107843399 x)\n"
          ]
        }
      ],
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x) # Target function to approximate\n",
        "\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "# [5e-2, 5e-4, 5e-6, 5e-8] 중 적절한 learning rate를 찾아주세요.\n",
        "# 적절한 learning rate보다 learning rate가 크거나 작을 때, 어떤 차이가 생기는지\n",
        "# 말씀해주세요.\n",
        "learning_rate = 5e-4\n",
        "\n",
        "# epoch = 2000\n",
        "for t in range(2000):\n",
        "    P3 = Legendre3Function.apply\n",
        "\n",
        "    # Forward pass: predict y.\n",
        "    # P3 using our custom backward function.\n",
        "    y_pred = a + b * P3(c + d*x)\n",
        "\n",
        "    # Compute and print MSE loss\n",
        "    loss = torch.mean((y_pred - y) ** 2)\n",
        "    #loss = (y_pred - y).pow(2).sum().mean()\n",
        "    \n",
        "    if t % 100 == 0:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Use autograd to compute the backward pass.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    # Hint : use a, b, c, d, learning_rate, a.grad, b.grad, c.grad, d.grad\n",
        "    with torch.no_grad():\n",
        "        a -= learning_rate * a.grad\n",
        "        b -= learning_rate * b.grad\n",
        "        c -= learning_rate * c.grad\n",
        "        d -= learning_rate * d.grad\n",
        "        \n",
        "        # Manually zero the gradients after updating weights\n",
        "        a.grad = a.grad.zero_()\n",
        "        b.grad = b.grad.zero_()\n",
        "        c.grad = c.grad.zero_()\n",
        "        d.grad = d.grad.zero_()\n",
        "\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM8VpY2Cz0_d"
      },
      "source": [
        "##Q5. Different Basis Function for approximating sine function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC_TprmP1n8J"
      },
      "source": [
        "이번에는 ReLu function을 사용하여 sine함수를 학습해보려 한다. \\\n",
        "ReLu function을 사용했을 때에도, 학습이 잘 되는지 살펴보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "6LOdtF9T0yqi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "99 0.4997005760669708\n",
            "199 0.49965062737464905\n",
            "299 0.49960067868232727\n",
            "399 0.49955081939697266\n",
            "499 0.49950098991394043\n",
            "599 0.4994511008262634\n",
            "699 0.4994012415409088\n",
            "799 0.4993514120578766\n",
            "899 0.49930158257484436\n",
            "999 0.4992517828941345\n",
            "1099 0.49920201301574707\n",
            "1199 0.499152272939682\n",
            "1299 0.49910253286361694\n",
            "1399 0.4990527927875519\n",
            "1499 0.4990031123161316\n",
            "1599 0.49895337224006653\n",
            "1699 0.498903751373291\n",
            "1799 0.49885401129722595\n",
            "1899 0.49880439043045044\n",
            "1999 0.4987547695636749\n",
            "Result: y = 0.0009978566085919738 + 1.0 * ReLu(-3.174852167830977e-07 + 1.0 x)\n"
          ]
        }
      ],
      "source": [
        "class ReLuFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        #return input.clamp(min=0)\n",
        "        return torch.clamp(input, min=0)\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[grad_input < 0] = 0\n",
        "        # Hint : reLu function의 도함수의 형태를 반영하면 됩니다.\n",
        "        return grad_input\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Our model : y = a + b * ReLu(c + d * x).\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.full((), 1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.full((), 1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 5e-7\n",
        "for t in range(2000):\n",
        "    ReLu = ReLuFunction.apply\n",
        "\n",
        "    # Forward pass: predict y.\n",
        "    # ReLu using our custom backward function.\n",
        "    y_pred = a * b * ReLu(c + d*x)\n",
        "\n",
        "    # Compute and print MSE loss\n",
        "    loss = torch.mean((y_pred-y)**2)\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Use autograd to compute the backward pass.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    # Hint : use a, b, c, d, learning_rate, a.grad, b.grad, c.grad, d.grad\n",
        "    with torch.no_grad():\n",
        "        a -= learning_rate * a.grad\n",
        "        b -= learning_rate * b.grad\n",
        "        c -= learning_rate * c.grad\n",
        "        d -= learning_rate * d.grad\n",
        "        \n",
        "        # Manually zero the gradients after updating weights\n",
        "        a.grad = a.grad.zero_()\n",
        "        b.grad = b.grad.zero_()\n",
        "        c.grad = c.grad.zero_()\n",
        "        d.grad = d.grad.zero_()\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} * ReLu({c.item()} + {d.item()} x)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJEtSsDc2gC9"
      },
      "source": [
        "## Q6. \n",
        "Q4, Q5에서 학습한 결과를 바탕으로, 어떤 function을 사용하는 것이 학습에 더 적절했었는지 코멘트해주세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1bkyVzf3xQI"
      },
      "source": [
        "## Q7. Deep Learning Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaLdpBPX4h0e"
      },
      "source": [
        "주어진 데이터를 로딩하고, 아래 코드의 빈칸을 채워\n",
        "딥러닝 학습을 하는 코드를 완성하여보자."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "B1so2sfQbpd5",
        "outputId": "ba125774-98ea-43b7-8a42-854d6fbb37d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4c7532dc-f451-4688-b107-10dc4b73fd7f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4c7532dc-f451-4688-b107-10dc4b73fd7f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving testX.csv to testX.csv\n",
            "Saving testY.csv to testY.csv\n",
            "Saving trainX.csv to trainX.csv\n",
            "Saving trainY.csv to trainY.csv\n"
          ]
        }
      ],
      "source": [
        "# 업로드 시간이 7분 30초 가량 걸리기에, 그동안 밑에 코드 작성 먼저 해주셔도 됩니다. (colab 사용시)\n",
        "# colab 사용하시면, 주석 지우고 사용해주세요\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "pp21KgUE4x8h"
      },
      "outputs": [],
      "source": [
        "# Data Loading using pd.read_csv\n",
        "\n",
        "train_X = pd.read_csv(\"trainX.csv\", header = None, encoding = 'utf-8')\n",
        "train_Y = pd.read_csv(\"trainY.csv\", header = None, encoding = 'utf-8')\n",
        "\n",
        "test_X = pd.read_csv(\"testX.csv\", header = None, encoding = 'utf-8')\n",
        "test_Y = pd.read_csv(\"testY.csv\", header = None, encoding = 'utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "l0-2JLqg441e"
      },
      "outputs": [],
      "source": [
        "# Data Setting\n",
        "train_X = np.array(train_X)\n",
        "train_Y = np.array(train_Y)\n",
        "\n",
        "test_X = np.array(test_X)\n",
        "test_Y = np.array(test_Y)\n",
        "\n",
        "input_dim = len(train_X[0])\n",
        "\n",
        "# Data type casting to torchTensor\n",
        "train_x = torch.FloatTensor(train_X)\n",
        "train_y = torch.FloatTensor(train_Y)\n",
        "\n",
        "# Set batch size\n",
        "batch_size = 4096\n",
        "dataset = TensorDataset(train_x, train_y)\n",
        "\n",
        "# DataLoader setting\n",
        "# 셔플이 있고, batch size에 맞게 dataloader를 세팅해주세요,\n",
        "dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "LV6Sgdv15nkM"
      },
      "outputs": [],
      "source": [
        "# Model Setting\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(input_dim, int(input_dim/6)),\n",
        "    # 각 Layer의 activation function을 설정해주세요.\n",
        "    torch.nn.ReLU(),\n",
        "    # Hint : hidden layer activation function ReLu\n",
        "    torch.nn.Linear(int(input_dim/6), int(input_dim/5)),\n",
        "    torch.nn.ReLU(),\n",
        "    # Hint : hidden layer activation function ReLu\n",
        "    torch.nn.Linear(int(input_dim/5), 1),\n",
        "    torch.nn.Sigmoid(),\n",
        "    # Hint : Output layer activation function for binary classification\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LLXeKJC6rIi",
        "outputId": "dd4ddeb2-3181-46d8-d467-37e503413449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of parameters: 1977 elements\n"
          ]
        }
      ],
      "source": [
        "params = list(model.parameters())\n",
        "print(\"The number of parameters:\", sum([p.numel() for p in model.parameters() if p.requires_grad]), \"elements\")\n",
        "x = torch.from_numpy(train_X.astype(np.float32))\n",
        "y = torch.from_numpy(train_Y.astype(np.float32)).view(-1, 1)\n",
        "\n",
        "# loss function 부분을 채워주세요.\n",
        "# BCE loss를 사용합니다.\n",
        "loss_fn = torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[11.9160,  7.9492,  0.6234,  ...,  2.3474,  0.5403,  5.7957],\n",
            "        [-6.5538, -0.7557,  0.7521,  ...,  4.6906,  6.4897,  2.5422],\n",
            "        [ 1.9634,  7.5538,  9.8412,  ...,  0.7196,  2.3400, -4.2287],\n",
            "        ...,\n",
            "        [-0.5099, -0.5238,  2.3014,  ...,  1.0998,  1.1777, -7.7745],\n",
            "        [ 3.0190,  4.8867, -4.7574,  ...,  8.0543,  9.8819,  0.0453],\n",
            "        [ 2.1500,  5.6854,  1.6438,  ...,  5.4736,  4.9149,  8.8774]])\n",
            "torch.Size([4096, 100])\n",
            "tensor([[ -7.2289,   6.4639,   0.4723,  ...,  -5.3620,   0.9606,   2.7308],\n",
            "        [  0.6807,  -4.1687,   7.0343,  ...,  -5.3656,   6.3480, -10.8060],\n",
            "        [  1.8875,   2.8457,  -2.8618,  ...,  -3.2862,   3.8450,   0.6044],\n",
            "        ...,\n",
            "        [  0.8668,  -0.0822,   2.7489,  ...,   4.6874,   4.2303,   1.3666],\n",
            "        [  1.1173,   2.8448,  -2.6263,  ...,   6.4338, -14.5917,   1.3880],\n",
            "        [ -4.5469,   0.7909,   5.9456,  ...,  -9.8783,   7.5069,   6.7853]])\n",
            "torch.Size([16000, 100])\n"
          ]
        }
      ],
      "source": [
        "print(trainx)\n",
        "print(trainx.shape)\n",
        "print(train_x)\n",
        "print(train_x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "xyGnAGQJ6Ihy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iter 0/200 loss: 0.7345\n",
            "iter 10/200 loss: 0.5753\n",
            "iter 20/200 loss: 0.5479\n",
            "iter 30/200 loss: 0.5288\n",
            "iter 40/200 loss: 0.5131\n",
            "iter 50/200 loss: 0.4963\n",
            "iter 60/200 loss: 0.4824\n",
            "iter 70/200 loss: 0.4678\n",
            "iter 80/200 loss: 0.4568\n",
            "iter 90/200 loss: 0.4483\n",
            "iter 100/200 loss: 0.4375\n",
            "iter 110/200 loss: 0.4320\n",
            "iter 120/200 loss: 0.4272\n",
            "iter 130/200 loss: 0.4230\n",
            "iter 140/200 loss: 0.4228\n",
            "iter 150/200 loss: 0.4165\n",
            "iter 160/200 loss: 0.4153\n",
            "iter 170/200 loss: 0.4129\n",
            "iter 180/200 loss: 0.4095\n",
            "iter 190/200 loss: 0.4147\n",
            "iter 200/200 loss: 0.4131\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 1e-3\n",
        "iter = 200\n",
        "loss_list = []\n",
        "# Adam optimizer를 설정해주세요. learning rate, 그리고 weight_decay는 5e-2로 설정해주세요.\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay=5e-2)\n",
        "\n",
        "prev_loss = 1e+30\n",
        "\n",
        "for t in range(iter+1):\n",
        "    for batch, sample in enumerate(dataloader):\n",
        "      trainx, trainy = sample\n",
        "      y_pred = model(trainx)\n",
        "\n",
        "      loss = loss_fn(y_pred, trainy)\n",
        "\n",
        "      # gradient 계산 및 gradient descent 계산을 통한 optimization 부분\n",
        "      # 코드를 채워주세요.\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "      loss_list.append(loss.item())\n",
        "\n",
        "    cur_loss = np.mean(loss_list[max(0, len(loss_list)-batch-1):len(loss_list)-1])\n",
        "    \n",
        "    if t % 10 == 0:\n",
        "      print('iter {}/{} loss: {:.4f}'.format(\n",
        "             t, iter, cur_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "uYrvNZ-68Y_L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weighted F1: 0.818689800707506\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x28cdf614d30>]"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "y_predict = model(torch.from_numpy(test_X.astype(np.float32)))\n",
        "y_pred = y_predict.detach().numpy()\n",
        "\n",
        "# test set의 prediction값을 계산하는 식을 작성하고, weighted f1 score를 계산해주세요.\n",
        "y_pred = [1.0 if x >= 0.5 else 0.0 for x in y_pred]\n",
        "result = f1_score(test_Y, y_pred, average=\"weighted\")\n",
        "\n",
        "# 결과물 출력\n",
        "print(\"Weighted F1:\", result)\n",
        "step = np.linspace(0, len(loss_list), len(loss_list))\n",
        "plt.plot(step/int(batch_size + 1), np.array(loss_list))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "jXzoKyGxv-aA",
        "DM8VpY2Cz0_d"
      ],
      "name": "pytorch_lab01.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
