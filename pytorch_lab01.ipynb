{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_lab01.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jXzoKyGxv-aA",
        "DM8VpY2Cz0_d"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjtirCJZF01L",
        "outputId": "d8be5d9a-1125-425d-b3a7-1827c3ecf3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install torch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader \n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q1 gradient descent로 simple linear regression 추정하기"
      ],
      "metadata": {
        "id": "qrdnwE-Ckd6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제로 사용할 데이터 생성하기\n",
        "\n",
        "$ y_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i \\quad \\epsilon_i \\sim  iid N(0, 1)$ \n",
        "\n",
        "$ \\beta_0 = 5, \\beta_1 = 2$라는 모형을 따르는 데이터를 생성해준다. "
      ],
      "metadata": {
        "id": "yV3I2XODkzpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_np = np.linspace(0, 10, 100).reshape(-1, 1)\n",
        "y_train_np = 2 *  x_train_np + 5 + norm.rvs(0, 1, size = len(x_train_np)).reshape(-1, 1)\n",
        "\n",
        "plt.scatter(x_train_np, y_train_np)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "DJuJTVrQmFel",
        "outputId": "dd10503e-bd27-41f6-8fce-26154b0c8e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$ \\hat{y_i} = \\beta_0 + \\beta_1 \\times x_i $\n",
        "\n",
        "$ \\hat{y_i} = bias + weight \\times x_i $\n",
        "\n",
        "gradient descent를 사용해 bias와 weight를 학습해보자. \n",
        "\n",
        "1) 추정된 bias와 weight의 결과값은 얼마인가? 그래프를 그려 실제 회귀식에 가깝게 추정되었는지를 확인해보자. "
      ],
      "metadata": {
        "id": "FdABaEaimr-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = torch.FloatTensor(x_train_np)\n",
        "y_train = torch.FloatTensor(y_train_np)\n",
        "\n",
        "W = torch.zeros(1, requires_grad = True) # Weight\n",
        "b = torch.zeros(1, requires_grad = True) # bias\n",
        "\n",
        "optimizer = optim.SGD([W, b], lr = 0.01)\n",
        "\n",
        "n_epochs = 1000\n",
        "for epoch in range(n_epochs + 1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  hypothesis = # your code here\n",
        "  \n",
        "  # cost 계산: MSE\n",
        "  cost = # your code here\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  # your code here\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "      print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "          epoch, n_epochs, W.item(), b.item(), cost.item()\n",
        "      ))"
      ],
      "metadata": {
        "id": "lt6LWxJRmTls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = W * x_train + b # 추정한 회귀식\n",
        "y_real = 2 * x_train + 5 # 실제 회귀식\n",
        "\n",
        "plt.plot(x_train_np, y_pred.detach().numpy())\n",
        "plt.plot(x_train_np, y_real.detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "CLKgfvzhaDu4",
        "outputId": "7c6df380-e78a-4df0-e514-1ed06fbab5f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5a0f47c510>]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) learning rate를 0.03으로 조정해보자. 어떠한 문제가 발생하는가?\n",
        "\n",
        "답: cost(MSE)가 최소가 되는 점을 찾지 못하고 발산한다. "
      ],
      "metadata": {
        "id": "yNA2S1mmqEvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 직접 W와 b를 정의하지 않고, nn.Module을 사용해 손쉽게 선형 모델을 생성할 수 있습니다. \n",
        "# 입출력값의 차원을 생각해 in_features와 out_features의 값을 적절하게 지정해주세요\n",
        "\n",
        "in_features = # your code here\n",
        "out_features = # your code here\n",
        "\n",
        "model = nn.Linear(in_features = in_features, out_features = out_features, bias = True)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.03)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    # H(x) 계산\n",
        "    hypothesis = model(x_train)\n",
        "    \n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(hypothesis, y_train)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 100번마다 로그 출력\n",
        "    if epoch % 100 == 0:\n",
        "        params = list(model.parameters())\n",
        "        W = params[0].item()\n",
        "        b = params[1].item()\n",
        "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, W, b, cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "id": "4gRKC_F_qcqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) learning rate를 0.00000001로 조정해보자. 어떠한 문제가 발생하는가?\n",
        "\n",
        "답: cost가 최소가 되는 점을 찾기까지 시간이 오래걸린다. epoch수를 늘리면 찾을수도 있지만 비효율적이다. "
      ],
      "metadata": {
        "id": "eoLOBBP4tBgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = torch.zeros(1, requires_grad = True) # Weight\n",
        "b = torch.zeros(1, requires_grad = True) # bias\n",
        "\n",
        "optimizer = optim.SGD([W, b], lr = 0.00000001)\n",
        "\n",
        "n_epochs = 1000\n",
        "for epoch in range(n_epochs + 1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  hypothesis = x_train * W + b \n",
        "  \n",
        "  # cost 계산: MSE\n",
        "  cost = torch.mean((hypothesis - y_train)**2) \n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "      print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
        "          epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
        "      ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L8OdKyqtNGq",
        "outputId": "532ff27f-e57a-4175-b1e6-5cc9332370bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 W: 0.000, b: 0.000 Cost: 260.390045\n",
            "Epoch  100/1000 W: 0.000, b: 0.000 Cost: 260.355286\n",
            "Epoch  200/1000 W: 0.000, b: 0.000 Cost: 260.320435\n",
            "Epoch  300/1000 W: 0.001, b: 0.000 Cost: 260.285675\n",
            "Epoch  400/1000 W: 0.001, b: 0.000 Cost: 260.250885\n",
            "Epoch  500/1000 W: 0.001, b: 0.000 Cost: 260.216064\n",
            "Epoch  600/1000 W: 0.001, b: 0.000 Cost: 260.181274\n",
            "Epoch  700/1000 W: 0.001, b: 0.000 Cost: 260.146545\n",
            "Epoch  800/1000 W: 0.001, b: 0.000 Cost: 260.111786\n",
            "Epoch  900/1000 W: 0.002, b: 0.000 Cost: 260.076965\n",
            "Epoch 1000/1000 W: 0.002, b: 0.000 Cost: 260.042236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q2. train set and test set - MNIST"
      ],
      "metadata": {
        "id": "TwmayIyvdT5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST dataset을 불러온다. "
      ],
      "metadata": {
        "id": "qckEHyW-t_EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "data_loader = DataLoader(dataset = mnist_train,\n",
        "                         batch_size = 100, \n",
        "                         shuffle = True\n",
        "                         )"
      ],
      "metadata": {
        "id": "u85modI7dZgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) epoch 수를 15로 설정하여 trainset을 훈련시켜보자. \n",
        "\n",
        "그 후 훈련시킨 모델로 testset에 대한 평가를 진행해보자. "
      ],
      "metadata": {
        "id": "GIuf-1TTuJkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train model with train sets\n",
        "\n",
        "# 입출력값의 차원을 생각해 in_features와 out_features의 값을 적절하게 지정해주세요\n",
        "\n",
        "in_features = # your code here\n",
        "out_features = # your code here\n",
        "linear = torch.nn.Linear(in_features = in_features, out_features=out_features, bias = True)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n",
        "\n",
        "training_epochs = 15\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = len(data_loader)\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28)\n",
        "        Y = Y\n",
        "\n",
        "        # H(x) 계산\n",
        "        hypothesis = linear(X)\n",
        "\n",
        "        # cost 계산\n",
        "        cost = criterion(hypothesis, Y)\n",
        "\n",
        "        #cost로 H(x) 개선\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
      ],
      "metadata": {
        "id": "a16aNA_xfH12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model using test sets\n",
        "with torch.no_grad(): # torch.no_grad()를 사용하는 이유를 간단하게 설명해봅시다. \n",
        "\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float()\n",
        "    Y_test = mnist_test.test_labels\n",
        "\n",
        "    prediction = linear(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())\n",
        "    print('cost:', cost.item())"
      ],
      "metadata": {
        "id": "piNVdn75gLKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) epoch 수를 30으로 설정하여 trainset을 훈련시켜보자. \n",
        "\n",
        "그 후 훈련시킨 모델로 testset에 대한 평가를 진행해보자. \n",
        "\n",
        "어떠한 문제가 발생하는가?"
      ],
      "metadata": {
        "id": "EkFfH5tsuY-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linear = torch.nn.Linear(784, 10, bias = True)\n",
        "criterion = torch.nn.CrossEntropyLoss()   \n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n",
        "\n",
        "training_epochs = 30\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = len(data_loader)\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        X = X.view(-1, 28 * 28)\n",
        "        Y = Y\n",
        "\n",
        "        # H(x) 계산\n",
        "        hypothesis = linear(X)\n",
        "\n",
        "        # cost 계산\n",
        "        cost = criterion(hypothesis, Y)\n",
        "\n",
        "        #cost로 H(x) 개선\n",
        "        optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "      print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))"
      ],
      "metadata": {
        "id": "rcrYS0wVhMlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model using test sets\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float()\n",
        "    Y_test = mnist_test.test_labels\n",
        "\n",
        "    prediction = linear(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    \n",
        "    print('Accuracy:', accuracy.item())\n",
        "    print('cost:', cost.item())"
      ],
      "metadata": {
        "id": "_g-hNozohXlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3. XOR problem with multilayer perceptron\n",
        "\n"
      ],
      "metadata": {
        "id": "y0mGZ5CpmCqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "Y = torch.FloatTensor([[0], [1], [0], [1]])\n",
        "\n",
        "# 입출력값의 차원을 고려하여 아래 빈칸을 적절하게 채워주세요\n",
        "linear1 = torch.nn.Linear('', '', bias = True)\n",
        "linear2 = torch.nn.Linear('', '', bias = True)\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "# 딥러닝의 구조를 고려하여 multi perceptron 모델을 적절하게 생성하세요. \n",
        "# nn.Sequential 함수를 사용하세요\n",
        "model =  # your code here\n",
        "\n",
        "# 이 예제에서 cross entropy 대신 BCE를 사용하는 이유를 간단하게 설명하세요\n",
        "criterion = torch.nn.BCELoss() \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1)\n",
        "\n",
        "for step in range(301):\n",
        "  hypothesis = model(X)\n",
        "  cost = criterion(hypothesis, Y)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "  if step%50 == 0:\n",
        "    print(step, cost.item())"
      ],
      "metadata": {
        "id": "v2HZ6xpRph0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4. Sine Function Approximation using the Legendre *Polynomial*"
      ],
      "metadata": {
        "id": "jXzoKyGxv-aA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "n = 3일때 르장드르 다항식은 다음과 같다. \\\n",
        "$ P_{3} = \\frac{1}{2} (5x^{3} -3x) $ \\\n",
        "이 함수를 사용하여, sine함수를 근사하도록 학습하려고 한다.\n"
      ],
      "metadata": {
        "id": "6B_VVc1nwJnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Forward, Backward 함수를 직접 작성하여보자."
      ],
      "metadata": {
        "id": "pE8kJ2AlwJ0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이 클래스에서, forward, backward 함수가 하는 기능이 무엇인지 설명해주세요.\n",
        "\n",
        "class Legendre3Function(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        return grad_output * 'your code here'\n",
        "        # Hint : Legendre Polynomial의 differential"
      ],
      "metadata": {
        "id": "IxykoRYDwIgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) 학습을 위한 parameter와 Data를 세팅해보자.\n",
        "   우리가 사용하려는 모델은 다음과 같다.\\\n",
        "   $ y = a + b * P_{3}(c + d * x) $"
      ],
      "metadata": {
        "id": "GrvjDnuxyGP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x) # Target function to approximate\n",
        "\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)"
      ],
      "metadata": {
        "id": "QeHfE-6tyFSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) 1)에서 정의한 forward, backward 함수를 사용하여,\n",
        "   딥러닝 학습 과정을 직접 작성해보자.\\\n",
        "   \\\n",
        "   Learning rate의 경우, 5e-2, 5e-4, 5e-6, 5e-8 중,\n",
        "   가장 적절한 Learning rate를 찾아보자. \\\n",
        "   적절한 learning rate보다 learning rate가 크거나 작을 때,\n",
        "   어떤 현상이 발생하는지 살펴보자."
      ],
      "metadata": {
        "id": "mKPsQrW5ywjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [5e-2, 5e-4, 5e-6, 5e-8] 중 적절한 learning rate를 찾아주세요.\n",
        "# 적절한 learning rate보다 learning rate가 크거나 작을 때, 어떤 차이가 생기는지\n",
        "# 말씀해주세요.\n",
        "learning_rate = 'your code here'\n",
        "\n",
        "# epoch = 2000\n",
        "for t in range(2000):\n",
        "    P3 = Legendre3Function.apply\n",
        "\n",
        "    # Forward pass: predict y.\n",
        "    # P3 using our custom backward function.\n",
        "    y_pred = 'your code here'\n",
        "\n",
        "    # Compute and print MSE loss\n",
        "    loss = 'your code here'\n",
        "    if t % 100 == 0:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Use autograd to compute the backward pass.\n",
        "    'your code here'\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    # Hint : use a, b, c, d, learning_rate, a.grad, b.grad, c.grad, d.grad\n",
        "    with torch.no_grad():\n",
        "        'your code here'\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        'your code here'\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
      ],
      "metadata": {
        "id": "bivK3PSHyjyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5. Different Basis Function for approximating sine function"
      ],
      "metadata": {
        "id": "DM8VpY2Cz0_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번에는 ReLu function을 사용하여 sine함수를 학습해보려 한다. \\\n",
        "ReLu function을 사용했을 때에도, 학습이 잘 되는지 살펴보자."
      ],
      "metadata": {
        "id": "MC_TprmP1n8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLuFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return 'your code here'\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        'your code here'\n",
        "        # Hint : reLu function의 도함수의 형태를 반영하면 됩니다.\n",
        "        return grad_input\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = 'your code here'\n",
        "\n",
        "# Our model : y = a + b * ReLu(c + d * x).\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.full((), 1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.full((), 1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 5e-7\n",
        "for t in range(2000):\n",
        "    ReLu = ReLuFunction.apply\n",
        "\n",
        "    # Forward pass: predict y.\n",
        "    # ReLu using our custom backward function.\n",
        "    y_pred = 'your code here'\n",
        "\n",
        "    # Compute and print MSE loss\n",
        "    loss = 'your code here'\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Use autograd to compute the backward pass.\n",
        "    'your code here'\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    # Hint : use a, b, c, d, learning_rate, a.grad, b.grad, c.grad, d.grad\n",
        "    with torch.no_grad():\n",
        "        'your code here'\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        'your code here'\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} * ReLu({c.item()} + {d.item()} x)')"
      ],
      "metadata": {
        "id": "6LOdtF9T0yqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q6. \n",
        "Q4, Q5에서 학습한 결과를 바탕으로, 어떤 function을 사용하는 것이 학습에 더 적절했었는지 코멘트해주세요."
      ],
      "metadata": {
        "id": "vJEtSsDc2gC9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q7. Deep Learning Example"
      ],
      "metadata": {
        "id": "s1bkyVzf3xQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "주어진 데이터를 로딩하고, 아래 코드의 빈칸을 채워\n",
        "딥러닝 학습을 하는 코드를 완성하여보자."
      ],
      "metadata": {
        "id": "aaLdpBPX4h0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 업로드 시간이 7분 30초 가량 걸리기에, 그동안 밑에 코드 작성 먼저 해주셔도 됩니다. (colab 사용시)\n",
        "# colab 사용하시면, 주석 지우고 사용해주세요\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "B1so2sfQbpd5",
        "outputId": "ba125774-98ea-43b7-8a42-854d6fbb37d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4c7532dc-f451-4688-b107-10dc4b73fd7f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4c7532dc-f451-4688-b107-10dc4b73fd7f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving testX.csv to testX.csv\n",
            "Saving testY.csv to testY.csv\n",
            "Saving trainX.csv to trainX.csv\n",
            "Saving trainY.csv to trainY.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading using pd.read_csv\n",
        "\n",
        "train_X = 'your code here'\n",
        "train_Y = 'your code here'\n",
        "\n",
        "test_X = 'your code here'\n",
        "test_Y = 'your code here'"
      ],
      "metadata": {
        "id": "pp21KgUE4x8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Setting\n",
        "train_X = np.array(train_X)\n",
        "train_Y = np.array(train_Y)\n",
        "\n",
        "test_X = np.array(test_X)\n",
        "test_Y = np.array(test_Y)\n",
        "\n",
        "input_dim = len(train_X[0])\n",
        "\n",
        "# Data type casting to torchTensor\n",
        "train_x = torch.FloatTensor(train_X)\n",
        "train_y = torch.FloatTensor(train_Y)\n",
        "\n",
        "# Set batch size\n",
        "batch_size = 4096\n",
        "dataset = TensorDataset(train_x, train_y)\n",
        "\n",
        "# DataLoader setting\n",
        "# 셔플이 있고, batch size에 맞게 dataloader를 세팅해주세요,\n",
        "dataloader = DataLoader(dataset, 'your code here')"
      ],
      "metadata": {
        "id": "l0-2JLqg441e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Setting\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(input_dim, int(input_dim/6)),\n",
        "    # 각 Layer의 activation function을 설정해주세요.\n",
        "    'your code here',\n",
        "    # Hint : hidden layer activation function ReLu\n",
        "    torch.nn.Linear(int(input_dim/6), int(input_dim/5)),\n",
        "    'your code here',\n",
        "    # Hint : hidden layer activation function ReLu\n",
        "    torch.nn.Linear(int(input_dim/5), 1),\n",
        "    'your code here',\n",
        "    # Hint : Output layer activation function for binary classification\n",
        "    )"
      ],
      "metadata": {
        "id": "LV6Sgdv15nkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(model.parameters())\n",
        "print(\"The number of parameters:\", sum([p.numel() for p in model.parameters() if p.requires_grad]), \"elements\")\n",
        "x = torch.from_numpy(train_X.astype(np.float32))\n",
        "y = torch.from_numpy(train_Y.astype(np.float32)).view(-1, 1)\n",
        "\n",
        "# loss function 부분을 채워주세요.\n",
        "# BCE loss를 사용합니다.\n",
        "loss_fn = 'your code here'"
      ],
      "metadata": {
        "id": "7LLXeKJC6rIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd4ddeb2-3181-46d8-d467-37e503413449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of parameters: 1977 elements\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "iter = 200\n",
        "loss_list = []\n",
        "# Adam optimizer를 설정해주세요. learning rate, 그리고 weight_decay는 5e-2로 설정해주세요.\n",
        "optimizer = 'your code here'(model.parameters(), 'your code here')\n",
        "\n",
        "prev_loss = 1e+30\n",
        "\n",
        "for t in range(iter+1):\n",
        "    for batch, sample in enumerate(dataloader):\n",
        "      trainx, trainy = sample\n",
        "      y_pred = model(trainx)\n",
        "\n",
        "      loss = 'your code here'\n",
        "\n",
        "      # gradient 계산 및 gradient descent 계산을 통한 optimization 부분\n",
        "      # 코드를 채워주세요.\n",
        "      'your code here'\n",
        "    \n",
        "      loss_list.append(loss.item())\n",
        "\n",
        "    cur_loss = np.mean(loss_list[max(0, len(loss_list)-batch-1):len(loss_list)-1])\n",
        "    \n",
        "    if t % 10 == 0:\n",
        "      print('iter {}/{} loss: {:.4f}'.format(\n",
        "             t, iter, cur_loss))"
      ],
      "metadata": {
        "id": "xyGnAGQJ6Ihy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = model(torch.from_numpy(test_X.astype(np.float32)))\n",
        "y_pred = y_predict.detach().numpy()\n",
        "\n",
        "# test set의 prediction값을 계산하는 식을 작성하고, weighted f1 score를 계산해주세요.\n",
        "y_pred = 'your code here'\n",
        "result = f1_score('your code here', average=\"weighted\")\n",
        "\n",
        "# 결과물 출력\n",
        "print(\"Weighted F1:\", result)\n",
        "step = np.linspace(0, len(loss_list), len(loss_list))\n",
        "plt.plot(step/int(batch_size + 1), np.array(loss_list))"
      ],
      "metadata": {
        "id": "uYrvNZ-68Y_L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}